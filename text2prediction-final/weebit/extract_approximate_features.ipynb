{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buidling Tenserflow version of the Readability Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and take `READABILITY_SCORES` and `POS_DENSITY` features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../data')\n",
    "from corpus import load_corpus\n",
    "data = load_corpus('weebit')\n",
    "\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "y_train_onehot = data['y_train_onehot']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']\n",
    "y_test_onehot = data['y_test_onehot']\n",
    "\n",
    "FEATURES_NAMES = data['FEATURES_NAMES']\n",
    "features = FEATURES_NAMES['READABILITY_SCORES'] + FEATURES_NAMES['POS_DENSITY']\n",
    "\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def threshold_socre(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred) <= 1) / len(y_true)\n",
    "\n",
    "def calc_scores(y_true, y_pred_probs):\n",
    "    y_pred_avg = (y_pred_probs * np.arange(5)).sum(axis=1)\n",
    "    y_pred_avg_classes = y_pred_avg.round().clip(0, 4).astype(int)\n",
    "    return {'accuracy': accuracy_score(y_true, y_pred_avg_classes),\n",
    "            'threshold': threshold_socre(y_true, y_pred_avg_classes)}\n",
    "\n",
    "threshold_scorer = make_scorer(threshold_socre)\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "def calc_scores_with_cv(model, X, y, cv=5):\n",
    "    return {'accuracy': np.mean(cross_val_score(model, X, y, scoring=accuracy_scorer, cv=cv)),\n",
    "            'threshold': np.mean(cross_val_score(model, X, y, scoring=threshold_scorer, cv=cv))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Softmax layer for the SVM Probabilites Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: {'accuracy': 0.6990836779451828, 'threshold': 0.9068099410863921}\n",
      "Test: {'accuracy': 0.6181318681318682, 'threshold': 0.929945054945055}\n",
      "Test - as normal classifier accuracy: 0.7060439560439561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_ovo = SVC(kernel='rbf', C=1, probability=True, decision_function_shape='ovo')\n",
    "\n",
    "print('CV:', calc_scores_with_cv(model_ovo, X_train, y_train))\n",
    "\n",
    "model_ovo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_ovo.predict(X_test)\n",
    "y_pred_probs = model_ovo.predict_proba(X_test)\n",
    "print('Test:', calc_scores(y_test, y_pred_probs))\n",
    "print('Test - as normal classifier accuracy:', model_ovo.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: {'accuracy': 0.7819762111775527, 'threshold': 0.9387866635910356}\n",
      "Test: {'accuracy': 0.6126373626373627, 'threshold': 0.9258241758241759}\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "def create_prob_calculator_ovo():\n",
    "    prob_calculator_ovo = Sequential()\n",
    "    prob_calculator_ovo.add(Dense(5, input_dim=10, activation='softmax'))\n",
    "\n",
    "    prob_calculator_ovo.compile(optimizer='rmsprop',\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "    return prob_calculator_ovo\n",
    "\n",
    "\n",
    "prob_calculator_ovo = KerasClassifier(build_fn=create_prob_calculator_ovo,\n",
    "                                      epochs=10, \n",
    "                                      verbose=0)\n",
    "\n",
    "\n",
    "X_dist_ovo_train = model_ovo.decision_function(X_train)\n",
    "X_dist_ovo_test = model_ovo.decision_function(X_test)\n",
    "\n",
    "print('CV:', calc_scores_with_cv(prob_calculator_ovo, X_dist_ovo_train, y_train))\n",
    "\n",
    "\n",
    "prob_calculator_ovo.fit(X_dist_ovo_train, y_train_onehot)\n",
    "\n",
    "y_pred_probs = prob_calculator_ovo.predict_proba(X_dist_ovo_test)\n",
    "print('Test:', calc_scores(y_test, y_pred_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /home/users/shlohod/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "\n",
    "TAG_REPLACER = {'NP'}\n",
    "[w.replace('NP', 'NN').replace(\"WP\",\"PR\").replace(\"WD\",\"DT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1161192/1161192 [00:08<00:00, 131586.00it/s]\n"
     ]
    }
   ],
   "source": [
    "word_tags = defaultdict(Counter)\n",
    "for word, pos in tqdm(brown.tagged_words()):\n",
    "    word_tags[word][pos] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'AT': 6725, 'AT-HL': 81, 'AT-TL': 452})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tags['The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
