{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n! pip install numpy\\n! pip install pandas\\n! pip install nltk\\n! pip install keras\\n! pip install matplotlib\\n! pip install sklearn\\n! pip install plotly\\n! pip install gensim\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installing dependencies\n",
    "\"\"\"\n",
    "! pip install numpy\n",
    "! pip install pandas\n",
    "! pip install nltk\n",
    "! pip install keras\n",
    "! pip install matplotlib\n",
    "! pip install sklearn\n",
    "! pip install plotly\n",
    "! pip install gensim\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vageesh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline \n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Input, merge, concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model,load_model\n",
    "\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "from numpy import linspace\n",
    "import inspect\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (3636, 2)\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "df = pd.read_hdf(\"weebit.h5\",\"text_df\")[['text','y']]\n",
    "# Dropping null values\n",
    "df.dropna(inplace=True)\n",
    "# Converting class labels to int dtype\n",
    "df['y'] = df['y'].astype(int)\n",
    "print(\"Shape of the dataset:\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text data\n",
    "def clean_text(text):\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"german\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)  \n",
    "    text = text.split()\n",
    "    stemmer = SnowballStemmer('german')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>very strict and 'old-fashioned'. would hit his...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the formula for finding the circumferenc circl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you need abl work out ris and fall temperatur ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ion are electrically charged particl formed wh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the poet arguing that this actually the way th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  y\n",
       "0  very strict and 'old-fashioned'. would hit his...  4\n",
       "1  the formula for finding the circumferenc circl...  4\n",
       "2  you need abl work out ris and fall temperatur ...  4\n",
       "3  ion are electrically charged particl formed wh...  4\n",
       "4  the poet arguing that this actually the way th...  4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].map(lambda x: clean_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26835 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Because of the computational expenses, I am using the top 20000 unique words. \n",
    "# At first, the text is tokenized and then convert those into sequences. \n",
    "# I have kept 50 words to limit the number of words in each comment.\n",
    "vocabulary_size = 20000\n",
    "\n",
    "# Initializing Tokenizer from keras\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "# Fitting text on the tokenizer\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "# Converting text to sequence\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "\n",
    "# Finding unique tokenizer\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# Padding sequences to the length of MAX_SEQUENCE_LENGTH\n",
    "data = pad_sequences(sequences, maxlen=50)\n",
    "labels = df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class labels from the corpora: [4 2 1 0 3]\n"
     ]
    }
   ],
   "source": [
    "unique_class_labels = df['y'].unique()\n",
    "print(\"class labels from the corpora:\",unique_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to modify elements of a dictionary\n",
    "class make_dict(dict):\n",
    "    def __getitem__(self, item):\n",
    "        try:\n",
    "            return dict.__getitem__(self, item)\n",
    "        except KeyError:\n",
    "            value = self[item] = type(self)()\n",
    "            return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of sentences in the Corpora is 3636\n",
      "No of sentences in class label 4 is 800\n",
      "No of sentences in class label 2 is 798\n",
      "No of sentences in class label 1 is 788\n",
      "No of sentences in class label 0 is 607\n",
      "No of sentences in class label 3 is 643\n"
     ]
    }
   ],
   "source": [
    "# Printing the total number of sentences in the corpora\n",
    "print(\"Total no of sentences in the Corpora is\",df.shape[0])\n",
    "# Getting count of sentences for every class\n",
    "count_list = []\n",
    "for class_label in df['y'].unique():\n",
    "    print(\"No of sentences in class label\",str(class_label) + \" is \" + str(df[df['y']==class_label].shape[0]))\n",
    "    count_list.append((str(class_label),int(df[df['y']==class_label].shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data into dictionary for plotting\n",
    "no_of_sentence = make_dict()\n",
    "for values in count_list:\n",
    "    no_of_sentence[values[0]] = values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHWVJREFUeJzt3XmYXXWd5/H3x7AJImGppGMSDEJEbZQQA9LSKgIqoE1ijxlQhIgZo/Og4NYKY4uidouPTqM4Sk8ahKAIIouklVYxwIALSAJhDZgYEMpEElkCiKx+5o/7K7kUJ7dOllO3qPq8nuc+95zf+d1zvydofe7Zfke2iYiI6O953S4gIiKGpgRERERUSkBERESlBERERFRKQERERKUEREREVEpAREREpQRE1Cbps5I+XqY/J+mADn2nSDq47vqaIGmGpBPK9JmS7pD0gbbvfk+//h+XZEk7lPn3SPrsAN+xr6Qzy/Thkm4sr19K2r2t35016r2zbfpbklZJurlfnzMl7TvAev66bZK2k3SppKXlfdv13LbpZbsWS1oo6e9L+yRJV5Tp10m6ta9mSW+TdOJA2x1DVwIi1ovtE2z/rEOXKUDHgBgEnwC+2Tb/T7b/vaqjpInAm4C7NuD77gDeYPtVwOeBuRuwrjOBAzfg832OAxbYngwsKPPrYwGwu+0pwHuB0/p3sH0Vz/xv/iPgEElbrud3RpclIKIjSZ+SdLuknwG7trWfKekdZXrP8ov5Bkm/lrQN8Dng0PKL89Aa3/M+Sf8l6fmSdpb0Y0mLJF0l6WWSti57AJuW/i+UdKekTSUdU3653ijp3LL8pcBjtv+4lq98GPhz2/zJtAKlfWiBP5d+nTwOrAGw/Uvb95f2q4EJbf1WD/Rv0N7H9pXAfRV91pTv7KR926YD88r0PGBGmV7XbXvYTw+7sBVP/zs9tZY6Kf2vAN42wPfEELVJtwuIoUvSq4HDgD1o/W/lOmBRvz6bAd8DDrV9raQXAo8AJwDTbH+wxvd8EHgzMMP2Y5LmAh+wvVTSa4Bv2t6vHMp4K/CDUtcFtp+QdBywU/ns6LLafUq9lWx/pe37DwF+b/sGSe19vjdQ7bZ/CfyyYtFs4L/a+u1ZY111+hxbo89X2mbH2l5Z2ldKGlOm13nbJL0d+CIwhtZ/B2zfDfxjh9UsBF4HnDfQ98XQk4CITl4HXGT7EQBJ8yv67AqstH0tgO0HS9+633EE0EsrHJ6Q9ALgtcD329axeXk/jdav/B8ARwHvK+03AmdL+kFZBjCOGr/ay+GPT9EKqI1C0htpBcTfb6x1DgW2LwIukvR6WofQ1noOqs0q4EWNFhaNySGmGMhAozmqRp9ObgYm8fThmOcBD9ie0vZ6OYDtXwCTJL0BGGW77wTuW4FvAK8GFknahNYhlC1qfP/OwE7ADeUk8QTgOkl/sz4bI+lVtIJsuu1712cdG9k9ksYBlPdVG7rCcvhr576T+QPYgmceyovnkAREdHIl8PZyXmBr4B8q+twGvEjSngDlXMEmwEPA1jW+43rg/cB8SS8qeyB3SJpZ1qf2q4GAs4BzgDPK8ucBE21fTmvvYjTwAmAJsMtAX277JttjbE+yPYnW3sxU239o7yfp7ZK+2GldknYELgSOsP2bDv1uG6iuOiR9sRz26WQ+MKtMzwIurlhPnW3bRWWXTtJUYDOgTgC+lNaPgHgOSkDEWtm+jtb5hcXABcBVFX0eBw4Fvi7pBuBSWr8aLwdeUeckte2fAx8HflR+lR4OzC7ru4XWidY+ZwPb0goJgFHAdyTdRCtsTrb9AK1w26Pvj9pGsDPw4AB9TgC2B77Zdzlo/w5l+wasSdI5wK+AXSX1Sppd0e2VwB8q2tudBLxJ0lJaV2mdVNGnzrb9N+BmSYtp7a0d2nbSupM30rqaKZ6DlOdBxHNJuXJquu0javT9GvCftn9Wruf/oe3z1/N7vwN8xHadq5E6redtwEtsn7Ih6ynr+ontt2yE9WyUbSvrmkTr33k3SWOB79ref0PXG92RgIjnDElfBw4CDu50CKet/1jgNbbnl7B4M/C1td0LERtG0uto3Xdyr+19y2HHJ2wv7nJpsZ4SENE4SUcB/S/P/IXto7tRT0TUk4CIiIhKOUkdERGVEhAREVEpAREREZUSEBERUSkBERERlRIQERFRKQERERGVEhAREVEpAREREZUSEBERUSkBERERlRIQERFRKQERERGVEhAREVEpAREREZU26XYBG2KHHXbwpEmTul1GRMRzyqJFi/5ou2egfs/pgJg0aRILFz7rufAREdGBpN/V6ZdDTBERUSkBERERlRIQERFRKQERERGVEhAREVGp0YCQ9BFJt0i6WdI5kraQtJOkayQtlfQ9SZuVvpuX+WVl+aQma4uIiM4aCwhJ44FjgGm2dwNGAYcBXwJOtj0ZuB+YXT4yG7jf9i7AyaVfRER0SdOHmDYBni9pE2BLYCWwH3B+WT4PmFGmp5d5yvL9Janh+iIiYi0aCwjbvwe+AtxFKxjWAIuAB2w/Wbr1AuPL9Hjg7vLZJ0v/7ZuqLyIiOmvsTmpJ29LaK9gJeAD4PnBQRVf3faTDsvb1zgHmAOy4444bpdYYWXTi8Nkx9Wee9X+R6CD/7ddNk4eYDgDusL3a9hPAhcBrgdHlkBPABGBFme4FJgKU5dsA9/Vfqe25tqfZntbTM+BQIhERsZ6aDIi7gL0lbVnOJewP3ApcDryj9JkFXFym55d5yvLLbOfnUURElzR2iMn2NZLOB64DngSuB+YCPwLOlfSF0nZ6+cjpwLclLaO153BYU7XF8NnVziGWiOY0Opqr7c8An+nXvBzYq6Lvo8DMJuuJiIj6cid1RERUSkBERESlBERERFRKQERERKUEREREVEpAREREpQRERERUSkBERESlBERERFRKQERERKUEREREVEpAREREpQRERERUSkBERESlBERERFRKQERERKUEREREVGosICTtKmlx2+tBSR+WtJ2kSyUtLe/blv6SdIqkZZJulDS1qdoiImJgjQWE7dttT7E9BXg18AhwEXAcsMD2ZGBBmQc4CJhcXnOAU5uqLSIiBjZYh5j2B35r+3fAdGBeaZ8HzCjT04Gz3HI1MFrSuEGqLyIi+hmsgDgMOKdMj7W9EqC8jynt44G72z7TW9oiIqILGg8ISZsBhwDfH6hrRZsr1jdH0kJJC1evXr0xSoyIiAqDsQdxEHCd7XvK/D19h47K+6rS3gtMbPvcBGBF/5XZnmt7mu1pPT09DZYdETGyDUZAvJOnDy8BzAdmlelZwMVt7UeWq5n2Btb0HYqKiIjBt0mTK5e0JfAm4P1tzScB50maDdwFzCztlwAHA8toXfF0VJO1RUREZ40GhO1HgO37td1L66qm/n0NHN1kPRERUV/upI6IiEoJiIiIqJSAiIiISgmIiIiolICIiIhKCYiIiKiUgIiIiEoJiIiIqJSAiIiISo3eSR0RQ49OrBo4+bnHn3nWYM+xkWUPIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKjUaEJJGSzpf0m2Slkj6O0nbSbpU0tLyvm3pK0mnSFom6UZJU5usLSIiOmt6D+JrwI9tvwzYHVgCHAcssD0ZWFDmAQ4CJpfXHODUhmuLiIgOGruTWtILgdcD7wGw/TjwuKTpwL6l2zzgCuCTwHTgrPJs6qvL3sc42ysbqW+Y3E0KuaM0IprR5B7ES4DVwBmSrpd0mqStgLF9f/TL+5jSfzxwd9vne0vbM0iaI2mhpIWrV69usPyIiJGtyYDYBJgKnGp7D+BPPH04qUrVT/pn/TS2Pdf2NNvTenp6Nk6lERHxLE0GRC/Qa/uaMn8+rcC4R9I4gPK+qq3/xLbPTwBWNFhfRER00FhA2P4DcLekXUvT/sCtwHxgVmmbBVxcpucDR5armfYG1jR1/iEiIgbW9HDfHwLOlrQZsBw4ilYonSdpNnAXMLP0vQQ4GFgGPFL6RkRElzQaELYXA9MqFu1f0dfA0U3WExER9eVO6oiIqJSAiIiISgMGhKRjJb2wnDw+XdJ1kt48GMVFRET31NmDeK/tB4E3Az20Th6f1GhVERHRdXUCou8GtoOBM2zfQPVNbRERMYzUCYhFkn5KKyB+Imlr4C/NlhUREd1W5zLX2cAUYLntRyRtT+5RiIgY9ursQRh4BXBMmd8K2KKxiiIiYkioExDfBP4OeGeZfwj4RmMVRUTEkFDnENNrbE+VdD2A7fvL0BkRETGM1dmDeELSKMrQ25J6yEnqiIhhr05AnAJcBIyR9C/Az4F/bbSqiIjougEPMdk+W9IiWgPsCZhhe0njlUVERFcNGBDl2Qy32P5Gmd9a0mvaHgQUERHDUJ1DTKcCD7fN/6m0RUTEMFZrqI3yrAYAbP+F5h80FBERXVYnIJZLOkbSpuV1LK2nw0VExDBWJyA+ALwW+D3QC7wGmFNn5ZLulHSTpMWSFpa27SRdKmlped+2tEvSKZKWSbpR0tT126SIiNgYBgwI26tsH2Z7jO2xtt9le9U6fMcbbU+x3ffo0eOABbYnAwvKPMBBwOTymkPOc0REdFWdq5h6gPcBk9r7237ven7ndGDfMj0PuAL4ZGk/q5zvuFrSaEnjbK9cz++JiIgNUOdk88XAVcDPgKfWcf0GfirJwP+1PRcY2/dH3/ZKSWNK3/HA3W2f7S1tzwgISXMoh7h23HHHdSwnIiLqqhMQW9r+5Hqufx/bK0oIXCrptg59qx5C5Gc1tEJmLsC0adOetTwiIjaOOiepfyjp4PVZue0V5X0VreE69gLukTQOoLz3nc/oBSa2fXwCsGJ9vjciIjZcnYA4llZIPCrpQUkPSXpwoA9J2qo8fQ5JW9F6pvXNwHxgVuk2i9YhLEr7keVqpr2BNTn/EBHRPXXGYtp6Pdc9FrhIUt/3fNf2jyVdC5wnaTZwFzCz9L+E1mNNlwGPkKfWRUR0VZ2rmAQcDuxk+/OSJgLjbP+60+dsLwd2r2i/l9bAf/3bDRxdt/CIiGjWujxR7l1l/mHyRLmIiGEvT5SLiIhKeaJcRERUWt8nyn2x0aoiIqLr8kS5iIioVOcqpm/bPgK4raItIiKGqTqHmP62faacj3h1M+VERMRQsdaAkHS8pIeAV7XdQf0QraExLl7b5yIiYnhYa0DY/mK5i/rLtl9oe+vy2t728YNYY0REdEGdk9THSxoPvJhnPg/iyiYLi4iI7qpzkvok4DDgVp5+HoSBBERExDBW507qtwO72n6s6WIiImLoqHMV03Jg06YLiYiIoaXOHsQjwGJJC4C/7kXYPqaxqiIiouvqBMT88oqIiBGkzlVM8yQ9H9jR9u2DUFNERAwBA56DkPQPwGLgx2V+iqTsUUREDHN1TlJ/FtgLeADA9mJgp7pfIGmUpOsl/bDM7yTpGklLJX2v79kSkjYv88vK8knruC0REbER1QmIJ22v6dfmdfiOY4H20V+/BJxsezJwPzC7tM8G7re9C3By6RcREV1SJyBulvQuYJSkyZK+DvyyzsolTQDeCpxW5gXsB5xfuswDZpTp6WWesnz/0j8iIrqgTkB8iNaIro8B5wAPAh+uuf6vAp/g6SfQbQ88YPvJMt8LjC/T44G7AcryNaX/M0iaI2mhpIWrV6+uWUZERKyrAQPC9iO2P2V7T+BNwD/bfnSgz0l6G7DK9qL25qqvqLGsvZ65tqfZntbT0zNQGRERsZ46Dfd9gqSXlenNJV0GLAPukXRAjXXvAxwi6U7gXFqHlr4KjJbUd3ntBGBFme4FJpbv2wTYBrhvnbcoIiI2ik57EIcCffc9zCp9xwBvAP51oBXbPt72BNuTaA32d5ntw4HLgXe0rbfv2RLzyzxl+WW21+VkeEREbESdAuLxtj/QbwHOsf1UeR51nTuw1+aTwEclLaN1juH00n46sH1p/yhw3AZ8R0REbKBOf+gfk7QbcA/wRuDjbcu2XJcvsX0FcEWZXk7rvor+fR4FZq7LeiMiojmdAuJYWpeb9tC6b+EOAEkHA9cPQm0REdFFaw0I29cAL6tovwS4pMmiIiKi++rcBxERESNQAiIiIip1ug9iZnmvPTBfREQMH532II4v7xcMRiERETG0dLqK6V5JlwM7VT3/wfYhzZUVERHd1ikg3gpMBb4N/O/BKSciIoaKTpe5Pg5cLem1tldL2rrV7IcHr7yIiOiWOlcxjZV0PXAzcKukReUO64iIGMbqBMRc4KO2X2x7R+BjpS0iIoaxOgGxle3L+2bKuEpbNVZRREQMCXVGZV0u6dO0TlYDvBu4o7mSIiJiKKizB/FeWgP2XVheOwBHNVlURER034B7ELbvB44ZhFoiImIIyVhMERFRKQERERGVGgsISVtI+rWkGyTdIunE0r6TpGskLZX0PUmblfbNy/yysnxSU7VFRMTABgwISRMkXSRptaR7JF0gaUKNdT8G7Gd7d2AKcKCkvYEv0XpC3WTgfmB26T8buN/2LsDJpV9ERHRJnT2IM4D5wDhgPPCfpa0jt/QNy7FpeRnYj9ajTAHmATPK9PQyT1m+vyTVqC8iIhpQJyB6bJ9h+8nyOpPWZa8DkjRK0mJgFXAp8FvgAdtPli69tEKH8n43QFm+Bti+Yp1zJC2UtHD16tV1yoiIiPVQJyD+KOnd5Y/9KEnvBu6ts3LbT9meAkwA9gJeXtWtvFftLfhZDfZc29NsT+vpqZVTERGxHureKPffgT8AK4F3lLbabD8AXAHsDYyW1Hf/xQRgRZnuBSYClOXbAPety/dERMTGM2BA2L7L9iG2e2yPsT3D9u8G+pykHkmjy/TzgQOAJcDltEIGYBZwcZmeX+Ypyy+z/aw9iIiIGBxrvZNa0gkdPmfbnx9g3eOAeZJG0Qqi82z/UNKtwLmSvgBcD5xe+p8OfFvSMlp7DofV3YiIiNj4Og218aeKtq1oXY66PdAxIGzfCOxR0b6c1vmI/u2PAjM7rTMiIgZPpyfK/fUxo+VpcsfSGqTvXPII0oiIYa/jYH2StgM+ChxO6x6FqWXwvoiIGOY6nYP4MvCPtJ4e98o8izoiYmTpdBXTx4AXAf8MrJD0YHk9JOnBwSkvIiK6pdM5iIz0GhExgiUEIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKjUWEJImSrpc0hJJt0g6trRvJ+lSSUvL+7alXZJOkbRM0o2SpjZVW0REDKzJPYgngY/ZfjmwN3C0pFcAxwELbE8GFpR5gIOAyeU1Bzi1wdoiImIAjQWE7ZW2ryvTDwFLgPHAdFpPp6O8zyjT04Gz3HI1MFrSuKbqi4iIzgblHISkScAewDXAWNsroRUiwJjSbTxwd9vHektb/3XNkbRQ0sLVq1c3WXZExIjWeEBIegFwAfBh252eRKeKNj+rwZ5re5rtaT09PRurzIiI6KfRgJC0Ka1wONv2haX5nr5DR+V9VWnvBSa2fXwCsKLJ+iIiYu2avIpJwOnAEtv/1rZoPjCrTM8CLm5rP7JczbQ3sKbvUFRERAy+tT6TeiPYBzgCuEnS4tL2v4CTgPMkzQbuAmaWZZcABwPLgEeAoxqsLSIiBtBYQNj+OdXnFQD2r+hv4Oim6omIiHWTO6kjIqJSAiIiIiolICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKiUgIiKiUpPPpP6WpFWSbm5r207SpZKWlvdtS7sknSJpmaQbJU1tqq6IiKinyT2IM4ED+7UdByywPRlYUOYBDgIml9cc4NQG64qIiBoaCwjbVwL39WueDswr0/OAGW3tZ7nlamC0pHFN1RYREQMb7HMQY22vBCjvY0r7eODutn69pe1ZJM2RtFDSwtWrVzdabETESDZUTlKros1VHW3PtT3N9rSenp6Gy4qIGLkGOyDu6Tt0VN5XlfZeYGJbvwnAikGuLSIi2gx2QMwHZpXpWcDFbe1HlquZ9gbW9B2KioiI7tikqRVLOgfYF9hBUi/wGeAk4DxJs4G7gJml+yXAwcAy4BHgqKbqioiIehoLCNvvXMui/Sv6Gji6qVoiImLdDZWT1BERMcQkICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKiUgIiKi0pAKCEkHSrpd0jJJx3W7noiIkWzIBISkUcA3gIOAVwDvlPSK7lYVETFyDZmAAPYCltlebvtx4FxgepdriogYsYZSQIwH7m6b7y1tERHRBbLd7RoAkDQTeIvt/1HmjwD2sv2hfv3mAHPK7K7A7YNa6LrbAfhjt4vokmz7yDWSt/+5sO0vtt0zUKdNBqOSmnqBiW3zE4AV/TvZngvMHayiNpSkhbandbuObsi2j8xth5G9/cNp24fSIaZrgcmSdpK0GXAYML/LNUVEjFhDZg/C9pOSPgj8BBgFfMv2LV0uKyJixBoyAQFg+xLgkm7XsZE9Zw6HNSDbPnKN5O0fNts+ZE5SR0TE0DKUzkFERMQQkoBoyEgeNkTStyStknRzt2sZbJImSrpc0hJJt0g6tts1DRZJW0j6taQbyraf2O2aukHSKEnXS/pht2vZUAmIBmTYEM4EDux2EV3yJPAx2y8H9gaOHkH/7R8D9rO9OzAFOFDS3l2uqRuOBZZ0u4iNIQHRjBE9bIjtK4H7ul1HN9heafu6Mv0QrT8UI2JEALc8XGY3La8RdZJT0gTgrcBp3a5lY0hANCPDhgSSJgF7ANd0t5LBUw6vLAZWAZfaHjHbXnwV+ATwl24XsjEkIJqhirYR9UtqpJP0AuAC4MO2H+x2PYPF9lO2p9AaCWEvSbt1u6bBIultwCrbi7pdy8aSgGhGrWFDYniStCmtcDjb9oXdrqcbbD8AXMHIOhe1D3CIpDtpHVbeT9J3ulvShklANCPDhoxQkgScDiyx/W/drmcwSeqRNLpMPx84ALitu1UNHtvH255gexKt/89fZvvdXS5rgyQgGmD7SaBv2JAlwHkjadgQSecAvwJ2ldQraXa3axpE+wBH0Pr1uLi8Du52UYNkHHC5pBtp/Ui61PZz/lLPkSx3UkdERKXsQURERKUEREREVEpAREREpQRERERUSkBERESlBESMCJL+RtK5kn4r6VZJl0h6qaRJTY06K+mzkj4+QJ8zJb1jHdbZWL0R/Q2pJ8pFNKHcvHYRMM/2YaVtCjCWZ46ZFRFtsgcRI8EbgSds/3tfg+3Ftq9q71R+nV8l6bryem1pHyfpynLT282SXlcGpTuzzN8k6SOdCpD0PknXlmclXCBpy7bFB5Tv/U0Zz6dv0Lsvl8/cKOn9Fev82/L8hcWlz+QN+UeK6C97EDES7AbUGUBtFfAm24+WP7bnANOAdwE/sf0v5VkfW9J63sF427sB9A0x0cGFtv+j9P0CMBv4elk2CXgDsDOtO5F3AY4E1tjeU9LmwC8k/ZRnDvr4AeBrts8uQ7qMqrGNEbUlICKetinwf8rhp6eAl5b2a4FvlUH4fmB7saTlwEskfR34EfDTAda9WwmG0cALaA3D0uc8238Blpb1vgx4M/CqtvMT2wCTgd+0fe5XwKfKMwgutL10/TY7oloOMcVIcAvw6hr9PgLcA+xOa89hM/jrA5BeD/we+LakI23fX/pdARzNwA+IORP4oO1XAicCW7Qt6z/ejWkNGf8h21PKayfbzwgh298FDgH+DPxE0n41tjGitgREjASXAZtLel9fg6Q9Jb2hX79tgJXl1/wRlEM2kl5Ma5z//6A1UutUSTsAz7N9AfBpYOoANWwNrCx7IYf3WzZT0vMk7Qy8BLid1h7G/yz9KVdcbdX+IUkvAZbbPoXWaMGvqvOPEVFXDjHFsGfbkt4OfFXSccCjwJ3Ah/t1/SZwgaSZwOXAn0r7vsA/SXoCeJjW+YHxwBmS+n5kHT9AGZ+m9WS53wE30QqMPrcD/4/WVVUfKOdATqN1buK6chXWamBGv3UeCry71PUH4HMD1BCxTjKaa0REVMohpoiIqJSAiIiISgmIiIiolICIiIhKCYiIiKiUgIiIiEoJiIiIqJSAiIiISv8fpkfdgZaBSO8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08cc0e10f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(list(no_of_sentence.keys()), no_of_sentence.values(), color='g')\n",
    "plt.suptitle(no_of_sentence.keys(), fontsize=10)\n",
    "plt.xlabel('Class labels', fontsize=10)\n",
    "plt.ylabel('No of Sentences', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (3636, 50)\n",
      "Shape of label tensor: (3636, 5)\n"
     ]
    }
   ],
   "source": [
    "# Getting the labels and features data\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the splitting index for training and testing data\n",
    "SPLIT_RATIO = 0.25\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "validation_samples = int(SPLIT_RATIO * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the testing and training dataset\n",
    "X_train = data[:-validation_samples]\n",
    "y_train = labels[:-validation_samples]\n",
    "X_test = data[-validation_samples:]\n",
    "y_test = labels[-validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using Using Convolutional neural network with multiple filter sizes(Deutsche lernen accuracy = 98.16%,Weebit Corpus accuracy=72.39%,GEO Corpus accuracy=86.84%)\n",
    "# (https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network starts with an embedding layer. The layer lets the system expand each token to a more massive vector, allowing the network to represent a word in a meaningful way. The layer takes 20000 as the first argument, which is the size of our vocabulary, and 100 as the second input parameter, which is the dimension of the embeddings. The third parameter is the input_length of 50, which is the length of each text sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the globals\n",
    "max_input_length = 50\n",
    "vocabulary_size = 20000\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sizes = (2,4,5,8)\n",
    "dropout_prob = [0.4,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vageesh/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "# Setting the Convolution layer\n",
    "graph_in = Input(shape=(max_input_length, embedding_dim))\n",
    "convs = []\n",
    "avgs = []\n",
    "\n",
    "for fsz in filter_sizes:\n",
    "    conv = Conv1D(nb_filter=32,filter_length=fsz,border_mode='valid',activation='relu',subsample_length=1)(graph_in)\n",
    "    pool = MaxPooling1D(pool_length = max_input_length - fsz + 1)(conv)\n",
    "    flattenMax = Flatten()(pool)\n",
    "    convs.append(flattenMax)\n",
    "\n",
    "if len(filter_sizes)>1:\n",
    "    out = concatenate(convs,axis=-1)\n",
    "else:\n",
    "    out = convs[0]\n",
    "\n",
    "graph = Model(input=graph_in, output=out, name=\"graphModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - CNN network\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "graphModel (Model)           (None, 128)               60928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 2,095,237\n",
      "Trainable params: 2,095,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2727 samples, validate on 909 samples\n",
      "Epoch 1/10\n",
      "2727/2727 [==============================] - 9s 3ms/step - loss: 1.4272 - acc: 0.3850 - val_loss: 1.0430 - val_acc: 0.5435\n",
      "Epoch 2/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.8842 - acc: 0.5831 - val_loss: 0.7670 - val_acc: 0.6282\n",
      "Epoch 3/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.7098 - acc: 0.6513 - val_loss: 0.6759 - val_acc: 0.6986\n",
      "Epoch 4/10\n",
      "2727/2727 [==============================] - 7s 2ms/step - loss: 0.5875 - acc: 0.7389 - val_loss: 0.6390 - val_acc: 0.7063\n",
      "Epoch 5/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.4637 - acc: 0.8122 - val_loss: 0.6045 - val_acc: 0.7239\n",
      "Epoch 6/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.3436 - acc: 0.8761 - val_loss: 0.6492 - val_acc: 0.7041\n",
      "Epoch 7/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.2324 - acc: 0.9182 - val_loss: 0.6876 - val_acc: 0.7206\n",
      "Epoch 8/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.1533 - acc: 0.9468 - val_loss: 0.7471 - val_acc: 0.7305\n",
      "Epoch 9/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.1036 - acc: 0.9663 - val_loss: 0.7720 - val_acc: 0.7283\n",
      "Epoch 10/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.0631 - acc: 0.9824 - val_loss: 0.9060 - val_acc: 0.7239\n"
     ]
    }
   ],
   "source": [
    "# Un-comment the below mentioned code to train your model\n",
    "\n",
    "# Configuring the neural network\n",
    "\"\"\"model_cnn = Sequential()\n",
    "model_cnn.add(Embedding(input_dim=vocabulary_size, output_dim = embedding_dim,input_length = max_input_length,trainable=True))\n",
    "model_cnn.add(Dropout(dropout_prob[0]))\n",
    "model_cnn.add(graph)\n",
    "model_cnn.add(Dense(256))\n",
    "model_cnn.add(Dropout(dropout_prob[1]))\n",
    "model_cnn.add(Activation('relu'))\n",
    "model_cnn.add(Dense(y_train.shape[1]))\n",
    "model_cnn.add(Activation('softmax'))\n",
    "model_cnn.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "print(\"model fitting - CNN network\")\n",
    "model_cnn.summary()\n",
    "# Training the model\n",
    "model_cnn.fit(X_train,y_train,validation_data=(X_test, y_test),epochs=10)\n",
    "# Saving the model\n",
    "model_cnn.save(\"simple_cnn.h5\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pre-trained model\n",
    "model_cnn = load_model(\"simple_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.39%\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy\n",
    "accuracy_model_cnn = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_model_cnn[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions in terms of probabilities for each class\n",
    "prediction_model_cnn = model_cnn.predict(X_test,batch_size=10,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4460735e-05, 1.1109689e-07, 1.8177912e-05, 2.0418435e-01,\n",
       "        7.9578292e-01],\n",
       "       [1.9133670e-02, 2.2691553e-02, 9.3409693e-01, 8.6950065e-05,\n",
       "        2.3990940e-02],\n",
       "       [1.4460735e-05, 1.1109689e-07, 1.8177912e-05, 2.0418435e-01,\n",
       "        7.9578292e-01],\n",
       "       ...,\n",
       "       [1.4460763e-05, 1.1109698e-07, 1.8177894e-05, 2.0418443e-01,\n",
       "        7.9578286e-01],\n",
       "       [1.4460763e-05, 1.1109698e-07, 1.8177894e-05, 2.0418443e-01,\n",
       "        7.9578286e-01],\n",
       "       [1.4460763e-05, 1.1109698e-07, 1.8177896e-05, 2.0418443e-01,\n",
       "        7.9578286e-01]], dtype=float32)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Using LSTM (Deutsche Lernen accuracy = 97.34%, Weebit Corpus accuracy = 72.83%,GEO Corpus accuracy=89.47%)\n",
    "# (https://arxiv.org/abs/1607.02501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - LSTM network\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 50, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 2,080,905\n",
      "Trainable params: 2,080,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2727 samples, validate on 909 samples\n",
      "Epoch 1/10\n",
      "2727/2727 [==============================] - 12s 4ms/step - loss: 1.1145 - acc: 0.4961 - val_loss: 0.8249 - val_acc: 0.5633\n",
      "Epoch 2/10\n",
      "2727/2727 [==============================] - 11s 4ms/step - loss: 0.7471 - acc: 0.6175 - val_loss: 0.8193 - val_acc: 0.5853\n",
      "Epoch 3/10\n",
      "2727/2727 [==============================] - 10s 3ms/step - loss: 0.6486 - acc: 0.7059 - val_loss: 0.7850 - val_acc: 0.6007\n",
      "Epoch 4/10\n",
      "2727/2727 [==============================] - 10s 4ms/step - loss: 0.5302 - acc: 0.7701 - val_loss: 0.6602 - val_acc: 0.7008\n",
      "Epoch 5/10\n",
      "2727/2727 [==============================] - 10s 4ms/step - loss: 0.3998 - acc: 0.8420 - val_loss: 0.7108 - val_acc: 0.6788\n",
      "Epoch 6/10\n",
      "2727/2727 [==============================] - 10s 4ms/step - loss: 0.3054 - acc: 0.8849 - val_loss: 0.8258 - val_acc: 0.6777\n",
      "Epoch 7/10\n",
      "2727/2727 [==============================] - 8s 3ms/step - loss: 0.2281 - acc: 0.9201 - val_loss: 0.7007 - val_acc: 0.7206\n",
      "Epoch 8/10\n",
      "2727/2727 [==============================] - 8s 3ms/step - loss: 0.1675 - acc: 0.9406 - val_loss: 0.7445 - val_acc: 0.7030\n",
      "Epoch 9/10\n",
      "2727/2727 [==============================] - 8s 3ms/step - loss: 0.1185 - acc: 0.9652 - val_loss: 1.2861 - val_acc: 0.6887\n",
      "Epoch 10/10\n",
      "2727/2727 [==============================] - 9s 3ms/step - loss: 0.0869 - acc: 0.9681 - val_loss: 0.8431 - val_acc: 0.7283\n"
     ]
    }
   ],
   "source": [
    "# Un-comment the below mentioned code to train your model\n",
    "\n",
    "\"\"\"# Configuring the neural network\n",
    "model_lstm  = Sequential()\n",
    "model_lstm.add(Embedding(vocabulary_size, 100, input_length=50))\n",
    "model_lstm.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(\"model fitting - LSTM network\")\n",
    "model_lstm.summary()\n",
    "# Training the model\n",
    "model_lstm.fit(X_train,y_train,validation_data=(X_test, y_test),epochs=10)\n",
    "# Saving the model\n",
    "model_lstm.save(\"simple_lstm.h5\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pre-trained model\n",
    "model_lstm = load_model(\"simple_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting model weights\n",
    "model_lstm_weights = model_lstm.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.83%\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy\n",
    "accuracy_model_lstm = model_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_model_lstm[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions in terms of probabilities for each class\n",
    "prediction_simple_lstm = model_lstm.predict(X_test,batch_size=10,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9091587e-06, 7.4576229e-07, 2.9338871e-06, 6.5963627e-06,\n",
       "        9.9998581e-01],\n",
       "       [3.5609847e-03, 3.6270227e-02, 9.5816475e-01, 6.5796595e-04,\n",
       "        1.3460962e-03],\n",
       "       [1.7649669e-03, 6.2734306e-01, 3.6965463e-01, 4.0003890e-04,\n",
       "        8.3731487e-04],\n",
       "       ...,\n",
       "       [9.9794513e-01, 2.0913327e-04, 3.2565265e-04, 2.5176944e-04,\n",
       "        1.2684127e-03],\n",
       "       [1.3937101e-02, 7.7337021e-01, 2.0892525e-01, 1.8109630e-03,\n",
       "        1.9564733e-03],\n",
       "       [8.7587781e-02, 4.4308495e-02, 8.4391236e-01, 7.6259230e-03,\n",
       "        1.6565368e-02]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_simple_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification using convolutional layer on top of the LSTM layer(Deutsch lernen accuracy = 97.90%, Weebit Corpus accuracy =66.61%,GEO corpus accuracy=85.71%)\n",
    "# (https://arxiv.org/pdf/1511.08630.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdding an one-dimensional CNN and max pooling layers after the Embedding layer which is then feed the \\nconsolidated features to the LSTM unit(to speed up the training proccess)\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adding an one-dimensional CNN and max pooling layers after the Embedding layer which is then feed the \n",
    "consolidated features to the LSTM unit(to speed up the training proccess)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - CNN-LSTM convolutional neural network\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 50, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 2,080,905\n",
      "Trainable params: 2,080,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2727 samples, validate on 909 samples\n",
      "Epoch 1/10\n",
      "2727/2727 [==============================] - 8s 3ms/step - loss: 1.2081 - acc: 0.4404 - val_loss: 0.7879 - val_acc: 0.5985\n",
      "Epoch 2/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.6446 - acc: 0.6806 - val_loss: 0.7080 - val_acc: 0.6271\n",
      "Epoch 3/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.3667 - acc: 0.8456 - val_loss: 0.7525 - val_acc: 0.6920\n",
      "Epoch 4/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.1699 - acc: 0.9428 - val_loss: 0.8634 - val_acc: 0.7074\n",
      "Epoch 5/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.0603 - acc: 0.9813 - val_loss: 1.2594 - val_acc: 0.6722\n",
      "Epoch 6/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.0401 - acc: 0.9897 - val_loss: 1.2393 - val_acc: 0.6799\n",
      "Epoch 7/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.0200 - acc: 0.9945 - val_loss: 1.4965 - val_acc: 0.6744\n",
      "Epoch 8/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.0132 - acc: 0.9967 - val_loss: 1.4208 - val_acc: 0.6667\n",
      "Epoch 9/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.0156 - acc: 0.9974 - val_loss: 1.7016 - val_acc: 0.6348\n",
      "Epoch 10/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 0.0205 - acc: 0.9941 - val_loss: 1.4752 - val_acc: 0.6612\n"
     ]
    }
   ],
   "source": [
    "# Un-comment the below mentioned code to train your model\n",
    "\n",
    "# Configuring the neural network\n",
    "\"\"\"model_conv = Sequential()\n",
    "model_conv.add(Embedding(vocabulary_size, 100, input_length=50))\n",
    "model_conv.add(Dropout(0.2))\n",
    "model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "model_conv.add(MaxPooling1D(pool_size=4))\n",
    "model_conv.add(LSTM(100))\n",
    "model_conv.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"model fitting - CNN-LSTM convolutional neural network\")\n",
    "model_lstm.summary()\n",
    "# Training the model\n",
    "model_conv.fit(X_train, y_train,validation_data=(X_test,y_test),epochs=10)\n",
    "# Saving the model\n",
    "model_conv.save(\"lstm_cnn.h5\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pre-trained model\n",
    "model_conv = load_model(\"lstm_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.12%\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy\n",
    "accuracy_model_conv = model_conv.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_model_conv[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions in terms of probabilities for each class\n",
    "prediction_model_conv = model_conv.predict(X_test,batch_size=10,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2412836e-04, 1.2691332e-04, 1.0445202e-04, 1.3600774e-01,\n",
       "        8.6363673e-01],\n",
       "       [6.6256282e-05, 5.8721198e-05, 1.4250492e-03, 1.4416560e-03,\n",
       "        9.9700838e-01],\n",
       "       [1.2412836e-04, 1.2691332e-04, 1.0445202e-04, 1.3600774e-01,\n",
       "        8.6363673e-01],\n",
       "       ...,\n",
       "       [1.2412813e-04, 1.2691320e-04, 1.0445192e-04, 1.3600767e-01,\n",
       "        8.6363679e-01],\n",
       "       [1.2412813e-04, 1.2691320e-04, 1.0445192e-04, 1.3600767e-01,\n",
       "        8.6363679e-01],\n",
       "       [1.2412813e-04, 1.2691320e-04, 1.0445192e-04, 1.3600767e-01,\n",
       "        8.6363679e-01]], dtype=float32)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre-trained Glove word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was trained on a dataset of one billion tokens (words) with a vocabulary of 400 thousand words. The glove has embedding vector sizes, including 50, 100, 200 and 300 dimensions. I will be choosing the 100-dimensional version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings from Glove\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using architecture having convolutional layer on top of the LSTM layer along with the globe word embeddings(Accuracy = 67.81%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - CNN-LSTM convolutional neural network with globe word embeddings\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 50, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 46, 64)            32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 2,098,569\n",
      "Trainable params: 98,569\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n",
      "Train on 2727 samples, validate on 909 samples\n",
      "Epoch 1/10\n",
      "2727/2727 [==============================] - 6s 2ms/step - loss: 1.2265 - acc: 0.4543 - val_loss: 0.8641 - val_acc: 0.6315\n",
      "Epoch 2/10\n",
      "2727/2727 [==============================] - 3s 1ms/step - loss: 0.7860 - acc: 0.6458 - val_loss: 0.7965 - val_acc: 0.6326\n",
      "Epoch 3/10\n",
      "2727/2727 [==============================] - 3s 1ms/step - loss: 0.6935 - acc: 0.6883 - val_loss: 0.7302 - val_acc: 0.6667\n",
      "Epoch 4/10\n",
      "2727/2727 [==============================] - 3s 1ms/step - loss: 0.6389 - acc: 0.7195 - val_loss: 0.7871 - val_acc: 0.6480\n",
      "Epoch 5/10\n",
      "2727/2727 [==============================] - 3s 1ms/step - loss: 0.5851 - acc: 0.7495 - val_loss: 0.7337 - val_acc: 0.6447\n",
      "Epoch 6/10\n",
      "2727/2727 [==============================] - 3s 1ms/step - loss: 0.5362 - acc: 0.7627 - val_loss: 0.6893 - val_acc: 0.6788\n",
      "Epoch 7/10\n",
      "2727/2727 [==============================] - 3s 1ms/step - loss: 0.4935 - acc: 0.7943 - val_loss: 0.7300 - val_acc: 0.6755\n",
      "Epoch 8/10\n",
      "2727/2727 [==============================] - 3s 1ms/step - loss: 0.4278 - acc: 0.8354 - val_loss: 0.7087 - val_acc: 0.6755\n",
      "Epoch 9/10\n",
      "2727/2727 [==============================] - 3s 1ms/step - loss: 0.3585 - acc: 0.8592 - val_loss: 0.7650 - val_acc: 0.6854\n",
      "Epoch 10/10\n",
      "2727/2727 [==============================] - 3s 1ms/step - loss: 0.2881 - acc: 0.8893 - val_loss: 0.8374 - val_acc: 0.6788\n"
     ]
    }
   ],
   "source": [
    "# Un-comment the below mentioned code to train your model\n",
    "\n",
    "# Configuring the neural network\n",
    "\"\"\"model_glove = Sequential()\n",
    "model_glove.add(Embedding(vocabulary_size, 100, input_length=50, weights=[embedding_matrix], trainable=False))\n",
    "model_glove.add(Dropout(0.2))\n",
    "model_glove.add(Conv1D(64, 5, activation='relu'))\n",
    "model_glove.add(MaxPooling1D(pool_size=4))\n",
    "model_glove.add(LSTM(100))\n",
    "model_glove.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model_glove.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"model fitting - CNN-LSTM convolutional neural network with globe word embeddings\")\n",
    "model_glove.summary()\n",
    "# Training the model\n",
    "model_glove.fit(X_train, y_train,validation_data=(X_test,y_test),epochs=10)\n",
    "# Saving the model\n",
    "model_glove.save(\"lstm_cnn_globe.h5\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pre-trained model\n",
    "model_glove_lstm_cnn = load_model(\"lstm_cnn_globe.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.88%\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy\n",
    "accuracy_model_glove_lstm_cnn = model_glove_lstm_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_model_glove_lstm_cnn[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions in terms of probabilities for each class\n",
    "prediction_model_glove_lstm_cnn = model_glove_lstm_cnn.predict(X_test,batch_size=10,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.4526103e-05, 5.5318833e-05, 1.1670993e-04, 1.0535414e-01,\n",
       "        8.9440936e-01],\n",
       "       [4.2728370e-04, 4.6679538e-04, 2.5911184e-03, 3.9599203e-03,\n",
       "        9.9255484e-01],\n",
       "       [6.4526103e-05, 5.5318833e-05, 1.1670993e-04, 1.0535414e-01,\n",
       "        8.9440936e-01],\n",
       "       ...,\n",
       "       [6.4526044e-05, 5.5318833e-05, 1.1670993e-04, 1.0535414e-01,\n",
       "        8.9440936e-01],\n",
       "       [6.4526044e-05, 5.5318833e-05, 1.1670993e-04, 1.0535414e-01,\n",
       "        8.9440936e-01],\n",
       "       [6.4526044e-05, 5.5318833e-05, 1.1670993e-04, 1.0535414e-01,\n",
       "        8.9440936e-01]], dtype=float32)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model_glove_lstm_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding visialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embedding weights\n",
    "cnn_embds = model_cnn.layers[0].get_weights()[0]\n",
    "lstm_embds = model_lstm.layers[0].get_weights()[0]\n",
    "conv_embds = model_conv.layers[0].get_weights()[0]\n",
    "glove_emds = model_glove.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating word list\n",
    "word_list = []\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of first two components of TSNE(t-distributed stochastic neighbor embedding)\n",
    "def plot_words(data, start, stop, step):\n",
    "    trace = go.Scatter(\n",
    "        x = data[start:stop:step,0], \n",
    "        y = data[start:stop:step, 1],\n",
    "        mode = 'markers',\n",
    "        text= word_list[start:stop:step]\n",
    "    )\n",
    "    layout = dict(title= 't-SNE 1 vs t-SNE 2',\n",
    "                  yaxis = dict(title='t-SNE 2'),\n",
    "                  xaxis = dict(title='t-SNE 1'),\n",
    "                  hovermode= 'closest')\n",
    "    fig = dict(data = [trace], layout= layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3be0c75d3999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn_tsne_embds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_embds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_tsne_embds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \"\"\"\n\u001b[0;32m--> 858\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    768\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                           skip_num_points=skip_num_points)\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_iter_without_progress'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             params, kl_divergence, it = _gradient_descent(obj_func, params,\n\u001b[0;32m--> 827\u001b[0;31m                                                           **opt_args)\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# Save the final number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose)\u001b[0m\n\u001b[1;32m    245\u001b[0m     error = _barnes_hut_tsne.gradient(val_P, X_embedded, neighbors, indptr,\n\u001b[1;32m    246\u001b[0m                                       \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                                       dof=degrees_of_freedom)\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "cnn_tsne_embds = TSNE(n_components=2).fit_transform(cnn_embds)\n",
    "plot_words(cnn_tsne_embds, 0, 2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "lstm_tsne_embds = TSNE(n_components=2).fit_transform(lstm_embds)\n",
    "plot_words(lstm_tsne_embds, 0, 2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN + LSTM\n",
    "conv_tsne_embds = TSNE(n_components=2).fit_transform(conv_embds)\n",
    "plot_words(conv_tsne_embds, 0, 2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN + LSTM + GLOVE\n",
    "glove_tsne_embds = TSNE(n_components=2).fit_transform(glove_emds)\n",
    "plot_words(glove_tsne_embds, 0, 2000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on geo data and predicting dw data using LSTM network(Accuracy = 55.52%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text data\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Takes an input as a text in string format along and clean it.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"german\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)  \n",
    "    text = text.split()\n",
    "    stemmer = SnowballStemmer('german')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(corpus):\n",
    "    \"\"\"\n",
    "    Takes an input as corpus name in string format along with its relative directory path.\n",
    "    \"\"\"\n",
    "    # Loading dataset\n",
    "    df = pd.read_hdf(corpus,\"text_df\")[['text','y']]\n",
    "    # Dropping null values\n",
    "    df.dropna(inplace=True)\n",
    "    # Converting class labels to int dtype\n",
    "    df['y'] = df['y'].astype(int)\n",
    "    print(\"Shape of the dataset:\",df.shape)\n",
    "    df['text'] = df['text'].map(lambda x: clean_text(x))\n",
    "    print(\"Dataset:\",df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sequence(df,vocabulary_size = 20000):\n",
    "    \"\"\"\n",
    "    Takes the dataframe, and returns the tokenized-sequenced features and labels.\n",
    "    \"\"\"\n",
    "    # Because of the computational expenses, I am using the top 20000 unique words. \n",
    "    # At first, the text is tokenized and then convert those into sequences. \n",
    "    # I have kept 50 words to limit the number of words in each comment.\n",
    "\n",
    "    # Initializing Tokenizer from keras\n",
    "    tokenizer = Tokenizer(nb_words=vocabulary_size)\n",
    "    # Fitting text on the tokenizer\n",
    "    tokenizer.fit_on_texts(df['text'])\n",
    "    # Converting text to sequence\n",
    "    sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "\n",
    "    # Finding unique tokenizer\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    # Padding sequences to the length of MAX_SEQUENCE_LENGTH\n",
    "    data = pad_sequences(sequences, maxlen=50)\n",
    "    labels = df['y']\n",
    "    \n",
    "    #performing one hot encoding on the labels\n",
    "    labels = to_categorical(np.asarray(labels))\n",
    "\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(corpus1_data,corpus1_labels,corpus2_data,corpus2_labels):\n",
    "    \"\"\"\n",
    "    Takes the labels and data from both the corpuses and considers the first corpus as the training corpus and \n",
    "    the second one as the testing corpus.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting the labels and features data\n",
    "    print('Shape of Corpus1 data tensor:', corpus1_data.shape)\n",
    "    print('Shape of Corpus1 label tensor:', corpus1_labels.shape)\n",
    "    \n",
    "    print('Shape of Corpus2 data tensor:', corpus2_data.shape)\n",
    "    print('Shape of Corpus2 label tensor:', corpus2_labels.shape)\n",
    "\n",
    "\n",
    "    X_train = corpus1_data\n",
    "    y_train = corpus1_labels\n",
    "    X_test = corpus2_data\n",
    "    y_test = corpus2_labels\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (2130, 2)\n",
      "Dataset:                                                 text  y\n",
      "0  kologie: dauerleck nordsee. seit jahr sprudelt...  1\n",
      "1  fischzug tiefe. herb vergang jahr brach polars...  1\n",
      "2  artikel 14.2.2004. landwirtschaft: geplatzt ge...  1\n",
      "3  artikel 28.8.2006. planet verschwind l sst ast...  1\n",
      "4  artikel 20.12.2010. verspielt seel wen igelf s...  1\n",
      "Found 77216 unique tokens.\n",
      "Shape of the dataset: (7814, 2)\n",
      "Dataset:                                                 text  y\n",
      "0  us-pr sident barack obama 250 zus tzlich solda...  1\n",
      "1  us-pr sident barack obama montag seit kanzleri...  1\n",
      "2  rechtspopulist fp bundespr sidentenwahl sterre...  1\n",
      "3  deutschland zahl fl chtling maghreb-staat alge...  1\n",
      "4  beid abgeschlag pr sidentschaftskandidat us-re...  1\n",
      "Found 49565 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Loading and preprocessing data\n",
    "geo_df = preprocess_data(\"geo.h5\")\n",
    "geo_data,geo_labels = tokenize_sequence(geo_df)\n",
    "\n",
    "dw_df = preprocess_data(\"dw.hdf5\")\n",
    "dw_data,dw_labels = tokenize_sequence(dw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Corpus1 data tensor: (2130, 50)\n",
      "Shape of Corpus1 label tensor: (2130, 2)\n",
      "Shape of Corpus2 data tensor: (7814, 50)\n",
      "Shape of Corpus2 label tensor: (7814, 2)\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into train and test corpus\n",
    "X_train,y_train,X_test,y_test = split_data(geo_data,geo_labels,dw_data,dw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - LSTM network\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 50, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 2,080,602\n",
      "Trainable params: 2,080,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2130 samples, validate on 7814 samples\n",
      "Epoch 1/10\n",
      "2130/2130 [==============================] - 16s 8ms/step - loss: 0.4606 - acc: 0.7991 - val_loss: 0.6780 - val_acc: 0.5997\n",
      "Epoch 2/10\n",
      "2130/2130 [==============================] - 14s 7ms/step - loss: 0.1615 - acc: 0.9488 - val_loss: 0.7728 - val_acc: 0.5930\n",
      "Epoch 3/10\n",
      "2130/2130 [==============================] - 12s 6ms/step - loss: 0.0579 - acc: 0.9831 - val_loss: 0.9430 - val_acc: 0.6097\n",
      "Epoch 4/10\n",
      "2130/2130 [==============================] - 13s 6ms/step - loss: 0.0335 - acc: 0.9934 - val_loss: 1.2056 - val_acc: 0.5854\n",
      "Epoch 5/10\n",
      "2130/2130 [==============================] - 13s 6ms/step - loss: 0.0133 - acc: 0.9967 - val_loss: 2.7487 - val_acc: 0.5136\n",
      "Epoch 6/10\n",
      "2130/2130 [==============================] - 14s 7ms/step - loss: 0.0125 - acc: 0.9972 - val_loss: 3.1279 - val_acc: 0.5110\n",
      "Epoch 7/10\n",
      "2130/2130 [==============================] - 14s 7ms/step - loss: 0.0129 - acc: 0.9977 - val_loss: 2.1539 - val_acc: 0.5312\n",
      "Epoch 8/10\n",
      "2130/2130 [==============================] - 14s 7ms/step - loss: 0.0061 - acc: 0.9991 - val_loss: 3.2454 - val_acc: 0.5660\n",
      "Epoch 9/10\n",
      "2130/2130 [==============================] - 14s 7ms/step - loss: 0.0094 - acc: 0.9991 - val_loss: 4.2136 - val_acc: 0.4950\n",
      "Epoch 10/10\n",
      "2130/2130 [==============================] - 16s 8ms/step - loss: 0.0121 - acc: 0.9977 - val_loss: 2.5514 - val_acc: 0.5572\n"
     ]
    }
   ],
   "source": [
    "# Un-comment the below mentioned code to train your model\n",
    "\n",
    "\"\"\"# Configuring the neural network\n",
    "model_lstm  = Sequential()\n",
    "model_lstm.add(Embedding(vocabulary_size, 100, input_length=50))\n",
    "model_lstm.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(\"model fitting - LSTM network\")\n",
    "model_lstm.summary()\n",
    "# Training the model\n",
    "model_lstm.fit(X_train,y_train,validation_data=(X_test, y_test),epochs=10)\n",
    "# Saving the model\n",
    "model_lstm.save(\"split_simple_geo_dw_lstm.h5\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pre-trained model\n",
    "model_lstm = load_model(\"split_simple_geo_dw_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.44%\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy\n",
    "accuracy_model_lstm = model_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_model_lstm[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class labels from the corpora: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Making predictions in terms of probabilities for each class\n",
    "prediction_simple_lstm = model_lstm.predict(X_test,batch_size=10,verbose=0)\n",
    "unique_class_labels = geo_df['y'].unique()\n",
    "print(\"class labels from the corpora:\",unique_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4964282e-03, 9.9850357e-01],\n",
       "       [6.3805408e-03, 9.9361938e-01],\n",
       "       [8.3556676e-01, 1.6443324e-01],\n",
       "       ...,\n",
       "       [8.8704962e-01, 1.1295045e-01],\n",
       "       [8.9980429e-04, 9.9910021e-01],\n",
       "       [9.9916077e-01, 8.3924638e-04]], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_simple_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution LSTM predictions:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f087d341198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Probability distribution LSTM predictions:\")\n",
    "plot_histogram(prediction_simple_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on dw data and predicting geo data using LSTM network(Accuracy = 99.99%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Corpus1 data tensor: (7814, 50)\n",
      "Shape of Corpus1 label tensor: (7814, 2)\n",
      "Shape of Corpus2 data tensor: (2130, 50)\n",
      "Shape of Corpus2 label tensor: (2130, 2)\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into train and test corpus\n",
    "X_train,y_train,X_test,y_test = split_data(dw_data,dw_labels,geo_data,geo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment the below mentioned code to train your model\n",
    "\n",
    "\"\"\"# Configuring the neural network\n",
    "model_lstm  = Sequential()\n",
    "model_lstm.add(Embedding(vocabulary_size, 100, input_length=50))\n",
    "model_lstm.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(\"model fitting - LSTM network\")\n",
    "model_lstm.summary()\n",
    "# Training the model\n",
    "model_lstm.fit(X_train,y_train,validation_data=(X_test, y_test),epochs=10)\n",
    "# Saving the model\n",
    "model_lstm.save(\"split_simple_dw_geo_lstm.h5\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.99%\n"
     ]
    }
   ],
   "source": [
    "# Loading the pre-trained model\n",
    "model_lstm = load_model(\"split_simple_dw_geo_lstm.h5\")\n",
    "\n",
    "# Checking the accuracy\n",
    "accuracy_model_lstm = model_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_model_lstm[1]*100))\n",
    "\n",
    "# Making predictions in terms of probabilities for each class\n",
    "prediction_simple_lstm = model_lstm.predict(X_test,batch_size=10,verbose=0)# Getting class prbabilities for every text in the corpus\n",
    "\n",
    "class_0,class_1 = ([] for i in range(2))\n",
    "for index,arrays in enumerate(prediction_simple_lstm):\n",
    "    class_0.append(arrays[0])\n",
    "    class_1.append(arrays[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data):\n",
    "    \n",
    "    class_label=dict()\n",
    "    class_label_0,class_label_1 = ([] for i in range(2))\n",
    "    \n",
    "    for arrays in data:\n",
    "        class_label_0.append(arrays[0])\n",
    "        class_label_1.append(arrays[1])\n",
    "    \n",
    "    class_label[0] = class_label_0\n",
    "    class_label[1] = class_label_1\n",
    "    \n",
    "    sns.set_context(\"paper\",font_scale=2)\n",
    "    sns.set_style(\"white\")\n",
    "    fig, ax = plt.subplots(figsize=(7,7),sharey=True)\n",
    "    sns.despine(left=True)\n",
    "    \n",
    "    labels=['class_label_0','class_label_1']\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        ax = sns.distplot(class_label[i],kde=False,label=labels[i],bins=20)\n",
    "    \n",
    "    ax.set_xlabel('Texts')\n",
    "    ax.set_ylabel('Probabilities')\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution LSTM predictions:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08666e4898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Probability distribution LSTM predictions:\")\n",
    "plot_histogram(prediction_simple_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Transfer learning on Weebit pre-trained Deutsche learnen Corpus(Using LSTM network(accuracy = 97.54%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (7814, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-Präsident Barack Obama will bis zu 250 zusä...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-Präsident Barack Obama wird an diesem Monta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die rechtspopulistische FPÖ hat bei der Bundes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In Deutschland ist die Zahl der Flüchtlinge au...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die beiden abgeschlagenen Präsidentschaftskand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  y\n",
       "0  US-Präsident Barack Obama will bis zu 250 zusä...  1\n",
       "1  US-Präsident Barack Obama wird an diesem Monta...  1\n",
       "2  Die rechtspopulistische FPÖ hat bei der Bundes...  1\n",
       "3  In Deutschland ist die Zahl der Flüchtlinge au...  1\n",
       "4  Die beiden abgeschlagenen Präsidentschaftskand...  1"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading necessary libraries\n",
    "dw_df = pd.read_hdf(\"dw.hdf5\",\"text_df\")[['text','y']]\n",
    "# Dropping null values\n",
    "dw_df.dropna(inplace=True)\n",
    "# Converting class labels to int dtype\n",
    "dw_df['y'] = dw_df['y'].astype(int)\n",
    "print(\"Shape of the dataset:\",dw_df.shape)\n",
    "dw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60833 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Because of the computational expenses, I am using the top 20000 unique words. \n",
    "# At first, the text is tokenized and then convert those into sequences. \n",
    "# I have kept 50 words to limit the number of words in each comment.\n",
    "vocabulary_size = 20000\n",
    "\n",
    "# Initializing Tokenizer from keras\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "# Fitting text on the tokenizer\n",
    "tokenizer.fit_on_texts(dw_df['text'])\n",
    "# Converting text to sequence\n",
    "sequences = tokenizer.texts_to_sequences(dw_df['text'])\n",
    "\n",
    "# Finding unique tokenizer\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# Padding sequences to the length of MAX_SEQUENCE_LENGTH\n",
    "data = pad_sequences(sequences, maxlen=50)\n",
    "labels = dw_df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class labels from the corpora: [1 0]\n",
      "Total no of sentences in the Corpora is 3636\n",
      "No of sentences in class label 1 is 6753\n",
      "No of sentences in class label 0 is 1061\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f087d30b518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_class_labels = dw_df['y'].unique()\n",
    "print(\"class labels from the corpora:\",unique_class_labels)\n",
    "\n",
    "# Used to modify elements of a dictionary\n",
    "class make_dict(dict):\n",
    "    def __getitem__(self, item):\n",
    "        try:\n",
    "            return dict.__getitem__(self, item)\n",
    "        except KeyError:\n",
    "            value = self[item] = type(self)()\n",
    "            return value\n",
    "\n",
    "# Printing the total number of sentences in the corpora\n",
    "print(\"Total no of sentences in the Corpora is\",df.shape[0])\n",
    "# Getting count of sentences for every class\n",
    "count_list = []\n",
    "for class_label in dw_df['y'].unique():\n",
    "    print(\"No of sentences in class label\",str(class_label) + \" is \" + str(dw_df[dw_df['y']==class_label].shape[0]))\n",
    "    count_list.append((str(class_label),int(dw_df[dw_df['y']==class_label].shape[0])))\n",
    "\n",
    "# Getting data into dictionary for plotting\n",
    "no_of_sentence = make_dict()\n",
    "for values in count_list:\n",
    "    no_of_sentence[values[0]] = values[1]\n",
    "\n",
    "plt.bar(list(no_of_sentence.keys()), no_of_sentence.values(), color='g')\n",
    "plt.suptitle(no_of_sentence.keys(), fontsize=10)\n",
    "plt.xlabel('Class labels', fontsize=10)\n",
    "plt.ylabel('No of Sentences', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (7814, 50)\n",
      "Shape of label tensor: (7814, 2)\n"
     ]
    }
   ],
   "source": [
    "# Getting the labels and features data\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# Getting the splitting index for training and testing data\n",
    "SPLIT_RATIO = 0.25\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "validation_samples = int(SPLIT_RATIO * data.shape[0])\n",
    "\n",
    "# Getting the testing and training dataset\n",
    "X_train = data[:-validation_samples]\n",
    "y_train = labels[:-validation_samples]\n",
    "X_test = data[-validation_samples:]\n",
    "y_test = labels[-validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training LSTM model on Deutche lernen corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - CNN-LSTM convolutional neural network with globe word embeddings\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 50, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 46, 64)            32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 2,098,266\n",
      "Trainable params: 2,098,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5861 samples, validate on 1953 samples\n",
      "Epoch 1/10\n",
      "5861/5861 [==============================] - 18s 3ms/step - loss: 0.2250 - acc: 0.9166 - val_loss: 0.0784 - val_acc: 0.9749\n",
      "Epoch 2/10\n",
      "5861/5861 [==============================] - 15s 2ms/step - loss: 0.0251 - acc: 0.9928 - val_loss: 0.0711 - val_acc: 0.9790\n",
      "Epoch 3/10\n",
      "5861/5861 [==============================] - 15s 3ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0938 - val_acc: 0.9764\n",
      "Epoch 4/10\n",
      "5861/5861 [==============================] - 15s 3ms/step - loss: 3.3208e-04 - acc: 0.9998 - val_loss: 0.1060 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      "5861/5861 [==============================] - 15s 3ms/step - loss: 4.1926e-05 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9764\n",
      "Epoch 6/10\n",
      "5861/5861 [==============================] - 15s 2ms/step - loss: 1.8513e-05 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9754\n",
      "Epoch 7/10\n",
      "5861/5861 [==============================] - 15s 3ms/step - loss: 1.8397e-05 - acc: 1.0000 - val_loss: 0.1301 - val_acc: 0.9754\n",
      "Epoch 8/10\n",
      "5861/5861 [==============================] - 15s 2ms/step - loss: 9.3011e-06 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9764\n",
      "Epoch 9/10\n",
      "5861/5861 [==============================] - 15s 3ms/step - loss: 7.1774e-06 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9759\n",
      "Epoch 10/10\n",
      "5861/5861 [==============================] - 15s 3ms/step - loss: 5.8218e-06 - acc: 1.0000 - val_loss: 0.1430 - val_acc: 0.9754\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 20000\n",
    "# Configuring the neural network\n",
    "\"\"\"model_transfer = Sequential()\n",
    "model_transfer.add(Embedding(vocabulary_size, 100, input_length=50, weights=[np.array(model_lstm_weights[0])], trainable=True))\n",
    "model_transfer.add(Dropout(0.2))\n",
    "model_transfer.add(Conv1D(64, 5, activation='relu'))\n",
    "model_transfer.add(MaxPooling1D(pool_size=4))\n",
    "model_transfer.add(LSTM(100))\n",
    "model_transfer.add(Dense(2, activation='softmax'))\n",
    "model_transfer.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"model fitting - CNN-LSTM convolutional neural network with globe word embeddings\")\n",
    "model_transfer.summary()\n",
    "# Training the model\n",
    "model_transfer.fit(X_train, y_train,validation_data=(X_test,y_test),epochs=10)\n",
    "# Saving the model\n",
    "model_transfer.save(\"lstm_cnn_transfer.h5\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pre-trained model\n",
    "model_transfer = load_model(\"lstm_cnn_transfer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.54%\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy\n",
    "accuracy_transfer_lstm_cnn = model_transfer.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_transfer_lstm_cnn[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions in terms of probabilities for each class\n",
    "prediction_model_transfer = model_transfer.predict(X_test,batch_size=10,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9359268e-06, 9.9999809e-01],\n",
       "       [2.0006737e-06, 9.9999797e-01],\n",
       "       [1.2755812e-06, 9.9999869e-01],\n",
       "       ...,\n",
       "       [8.3632258e-06, 9.9999166e-01],\n",
       "       [9.9999321e-01, 6.8041945e-06],\n",
       "       [1.1049656e-06, 9.9999893e-01]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model_transfer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
